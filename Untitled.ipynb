{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "classes = list(set(df.label.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.utils' has no attribute 'multi_gpu_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6880157dfdd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mktrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mktrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArrayLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelease_gpu_memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageClassLearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTTextClassLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerTextClassLearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\imports.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[0mplot_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mto_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[0mmulti_gpu_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_gpu_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0msigmoid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.utils' has no attribute 'multi_gpu_model'"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>917</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>581</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tennis</th>\n",
       "      <td>393</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  content\n",
       "label                        \n",
       "business         917      917\n",
       "crime            581      581\n",
       "entertainment    486      486\n",
       "politics         525      525\n",
       "tennis           393      393"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[df.label.isin([\"crime\", \"tennis\", \"politics\", \"business\", \"entertainment\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'title', 'content', 'processed', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample[[\"title\", \"processed\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.rename(columns={\"processed\": \"content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83984</th>\n",
       "      <td>Teen Climate Activist Greta Thunberg Has Been ...</td>\n",
       "      <td>greta thunberg yearold swedish activist headli...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148902</th>\n",
       "      <td>Dominic Thiem net worth: How much is French Op...</td>\n",
       "      <td>reuters dominic thiem compete grand slam final...</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50588</th>\n",
       "      <td>Pype Launches Revolutionary AI and Machine Lea...</td>\n",
       "      <td>smartplans major offering pype automates proce...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15099</th>\n",
       "      <td>Woman pleads guilty to poisoning husband with ...</td>\n",
       "      <td>aug book photo provide york county sheriff off...</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49870</th>\n",
       "      <td>NOW WATCH THIS: New Crypto-Collectible Watch F...</td>\n",
       "      <td>watch skin corp launch world marketplace block...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46854</th>\n",
       "      <td>Reyes Holdings sells Reinhart Foodservice</td>\n",
       "      <td>rosemont reyes holding sell reinhart foodservi...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145153</th>\n",
       "      <td>Revived and refocused, Simona Halep stands mot...</td>\n",
       "      <td>difference simona halep open world reign grand...</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>Police launch review of boy’s arrest after vid...</td>\n",
       "      <td>watch sacramento police arrest yearold boy sac...</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146701</th>\n",
       "      <td>French Open 2019 prize money: How much will th...</td>\n",
       "      <td>rench open organiser upped prize money cent ri...</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145213</th>\n",
       "      <td>Roger Federer v Rafael Nadal: ranking their 12...</td>\n",
       "      <td>french open final nadal comfortably onesided m...</td>\n",
       "      <td>tennis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "83984   Teen Climate Activist Greta Thunberg Has Been ...   \n",
       "148902  Dominic Thiem net worth: How much is French Op...   \n",
       "50588   Pype Launches Revolutionary AI and Machine Lea...   \n",
       "15099   Woman pleads guilty to poisoning husband with ...   \n",
       "49870   NOW WATCH THIS: New Crypto-Collectible Watch F...   \n",
       "46854           Reyes Holdings sells Reinhart Foodservice   \n",
       "145153  Revived and refocused, Simona Halep stands mot...   \n",
       "11981   Police launch review of boy’s arrest after vid...   \n",
       "146701  French Open 2019 prize money: How much will th...   \n",
       "145213  Roger Federer v Rafael Nadal: ranking their 12...   \n",
       "\n",
       "                                                  content     label  \n",
       "83984   greta thunberg yearold swedish activist headli...  politics  \n",
       "148902  reuters dominic thiem compete grand slam final...    tennis  \n",
       "50588   smartplans major offering pype automates proce...  business  \n",
       "15099   aug book photo provide york county sheriff off...     crime  \n",
       "49870   watch skin corp launch world marketplace block...  business  \n",
       "46854   rosemont reyes holding sell reinhart foodservi...  business  \n",
       "145153  difference simona halep open world reign grand...    tennis  \n",
       "11981   watch sacramento police arrest yearold boy sac...     crime  \n",
       "146701  rench open organiser upped prize money cent ri...    tennis  \n",
       "145213  french open final nadal comfortably onesided m...    tennis  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/55/d1/a3631a36859ee324e1767fa7554fdf7af17965571d8537b20b311b76bcfe/tensorflow-2.11.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting tensorflow-intel==2.11.0; platform_system == \"Windows\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/8c/18288ac12dc0e1997c73f1b86dbd6f7fa3674ae5341769387e1f13b07c9e/tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/c5/265da99011dbe91cb18cba88e14397bddf8a286512866b8ffe83bc17e58b/libclang-16.0.0-py2.py3-none-win_amd64.whl\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/de/44/bf1b0eef5b13e6201aef076ff34b91bc40aace8591cd273c1c2a94a9cc00/keras-2.11.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b1/8b/f4c02cf1f841dede987f93c37d42256dc4a82cd07173ad8a5458eee1c412/wrapt-1.15.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/77/e624b4916531721e674aa105151ffa5223fb224d3ca4bd5c10574664f944/tensorboard-2.11.2-py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/87/de5c32fa1b1c6c3305d576e299801d8655c175ca9557019906247b994331/absl_py-1.4.0-py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/e1/434566ffce04448192369c1a282931cf4ae593e91907558eaecd2e9f2801/termcolor-2.3.0-py3-none-any.whl\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/f7/ed1d9dcf12b867a7d4de8b2644932ea0b11d2355f2fa11222deba06576d3/grpcio-1.56.0-cp37-cp37m-win_amd64.whl (4.2MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/e2/8bf618c7c30a525054230ee6d40b036d3e5abc2c4ff67cf7c7420a519204/tensorflow_estimator-2.11.0-py2.py3-none-any.whl\n",
      "Collecting packaging (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c3/57f0601a2d4fe15de7a553c00adbc901425661bf048f2a22dfc500caf121/packaging-23.1-py3-none-any.whl\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mlflow 1.30.1 has requirement importlib-metadata!=4.7.0,<6,>=3.7.0, but you'll have importlib-metadata 6.7.0 which is incompatible.\n",
      "mlflow 1.30.1 has requirement packaging<22, but you'll have packaging 23.1 which is incompatible.\n",
      "Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'd:\\\\mlflowenv\\\\lib\\\\site-packages\\\\~arkupsafe\\\\_speedups.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "You are using pip version 19.0.3, however version 23.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/b1/1702140b92543318ecca7ed502fcb18085a9d5760058cf9ea2310bb8dbd6/tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/44/c6/ebb183fcd341681fe41d86b10790335c27372dd279189ab514c75acdbfb2/h5py-3.8.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting numpy>=1.20 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/9f/da37cc4a188a1d5d203d65ab28d6504e17594b5342e0c1dc5610ee6f4535/numpy-1.21.6-cp37-cp37m-win_amd64.whl\n",
      "Collecting six>=1.12.0 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/ee/e3562fd4e692afc6ed396b60ce3a177bc4ce6506ac8ac2413886198880e3/protobuf-3.19.6-cp37-cp37m-win_amd64.whl\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/86/cc8d1ff2ca31a312a25a708c891cf9facbad4eae493b3872638db6785eb5/wheel-0.40.0-py3-none-any.whl\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/9c/8d/bff87fc722553a5691d8514da5523c23547f3894189ba03b57592e37bdc2/google_auth-2.22.0-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/a1/1352b0e5a3c71a79fa9265726e2217f69df9fd4de0bcb5725cc61f62a5df/Markdown-3.4.3-py3-none-any.whl\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f6/f8/9da63c1617ae2a1dec2fbf6412f3a0cfe9d4ce029eccbda6e1e4258ca45f/Werkzeug-2.2.3-py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b1/0e/0636cc1448a7abc444fb1b3a63655e294e0d2d49092dc3de05241be6d43c/google_auth_oauthlib-0.4.6-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/68/e8ecfac5dd594b676c23a7f07ea34c197d7d69b3313afdf8ac1b0a9905a2/tensorboard_plugin_wit-1.8.1-py3-none-any.whl\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/69/5747a957f95e2e1d252ca41476ae40ce79d70d38151d2e494feb7722860c/tensorboard_data_server-0.6.1-py3-none-any.whl\n",
      "Collecting urllib3<2.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl (143kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/8e/bea464350e1b8c6ed0da3a312659cb648804a08af6cacc6435867f74f8bd/pyasn1_modules-0.3.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\" (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/94/64287b38c7de4c90683630338cf28f129decbba0a44f0c6db35a873c73c4/importlib_metadata-6.7.0-py3-none-any.whl\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/9b/c1/9f44da5ca74f95116c644892152ca6514ecdc34c8297a3f40d886147863d/MarkupSafe-2.1.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/9f/552f15cb1dade9332d6f0208fa3e6c21bb3eecf1c89862413ed8a3c75900/charset_normalizer-3.2.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/19/59961b522e6757f0c9097e4493fa906031b95b3ebe9360b2c3083561a6b4/certifi-2023.5.7-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/e5/b56a725cbde139aa960c26a1a3ca4d4af437282e20b5314ee6a3501e7dfc/pyasn1-0.5.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/fa/c9e82bbe1af6266adf08afb563905eb87cab83fde00a0a08963510621047/zipp-3.15.0-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl\n",
      "Installing collected packages: gast, libclang, keras, setuptools, wrapt, six, wheel, astunparse, urllib3, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, numpy, typing-extensions, zipp, importlib-metadata, markdown, MarkupSafe, werkzeug, oauthlib, charset-normalizer, certifi, idna, requests, requests-oauthlib, google-auth-oauthlib, protobuf, grpcio, tensorboard-plugin-wit, tensorboard-data-server, absl-py, tensorboard, google-pasta, opt-einsum, termcolor, tensorflow-estimator, packaging, flatbuffers, tensorflow-io-gcs-filesystem, h5py, tensorflow-intel, tensorflow\n",
      "  Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Found existing installation: libclang 16.0.0\n",
      "    Uninstalling libclang-16.0.0:\n",
      "      Successfully uninstalled libclang-16.0.0\n",
      "  Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "  Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "  Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Found existing installation: wheel 0.40.0\n",
      "    Uninstalling wheel-0.40.0:\n",
      "      Successfully uninstalled wheel-0.40.0\n",
      "  Found existing installation: astunparse 1.6.3\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "  Found existing installation: urllib3 1.26.6\n",
      "    Uninstalling urllib3-1.26.6:\n",
      "      Successfully uninstalled urllib3-1.26.6\n",
      "  Found existing installation: pyasn1 0.5.0\n",
      "    Uninstalling pyasn1-0.5.0:\n",
      "      Successfully uninstalled pyasn1-0.5.0\n",
      "  Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Found existing installation: pyasn1-modules 0.3.0\n",
      "    Uninstalling pyasn1-modules-0.3.0:\n",
      "      Successfully uninstalled pyasn1-modules-0.3.0\n",
      "  Found existing installation: cachetools 5.3.1\n",
      "    Uninstalling cachetools-5.3.1:\n",
      "      Successfully uninstalled cachetools-5.3.1\n",
      "  Found existing installation: google-auth 2.22.0\n",
      "    Uninstalling google-auth-2.22.0:\n",
      "      Successfully uninstalled google-auth-2.22.0\n",
      "  Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Found existing installation: typing-extensions 4.7.1\n",
      "    Uninstalling typing-extensions-4.7.1:\n",
      "      Successfully uninstalled typing-extensions-4.7.1\n",
      "  Found existing installation: zipp 3.15.0\n",
      "    Uninstalling zipp-3.15.0:\n",
      "      Successfully uninstalled zipp-3.15.0\n",
      "  Found existing installation: importlib-metadata 5.2.0\n",
      "    Uninstalling importlib-metadata-5.2.0:\n",
      "      Successfully uninstalled importlib-metadata-5.2.0\n",
      "  Found existing installation: Markdown 3.4.3\n",
      "    Uninstalling Markdown-3.4.3:\n",
      "      Successfully uninstalled Markdown-3.4.3\n",
      "  Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/de/44/bf1b0eef5b13e6201aef076ff34b91bc40aace8591cd273c1c2a94a9cc00/keras-2.11.0-py2.py3-none-any.whl\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "Successfully installed keras-2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 23.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/34/6720c227e26638260eca1110ae200e0844bdbe6154b49e3aecd8392e95ae/ktrain-0.37.2.tar.gz (25.3MB)\n",
      "Collecting scikit-learn (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/20/0ffe8665a44bce7616bd33d4368a198fecad3b226bcafa38c63ef0f6286f/scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting matplotlib>=3.0.0 (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/df/3f/6093a23565d0f50ce433f56223fcc34af6c912cd4331dc582ba29d9b5a17/matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2MB)\n",
      "Collecting pandas>=1.0.1 (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/56/f886ed6f1777ffa9d54c6e80231b69db8a1f52dcc33f5967b06a105dcfe0/pandas-1.3.5-cp37-cp37m-win_amd64.whl\n",
      "Collecting fastprogress>=0.1.21 (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/8f/213223fdee199c55db81e2d0c669f30e8285c5be2526c4ed924de39247da/fastprogress-1.0.3-py3-none-any.whl\n",
      "Collecting requests (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mlflow 1.30.1 has requirement importlib-metadata!=4.7.0,<6,>=3.7.0, but you'll have importlib-metadata 6.7.0 which is incompatible."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/08/9dcdaa5aac4634e4c23af26d92121f7ce445c630efa0d3037881ae2407fb/joblib-1.3.1-py3-none-any.whl\n",
      "Collecting packaging (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/c3/57f0601a2d4fe15de7a553c00adbc901425661bf048f2a22dfc500caf121/packaging-23.1-py3-none-any.whl (48kB)\n",
      "Collecting langdetect (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz\n",
      "Collecting jieba (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz\n",
      "Collecting cchardet (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/e6/ecd8bb8440ad5c8b7cdb4d0c3fb1e7e653fc9b49c6feca4fce81bbc744a2/cchardet-2.1.7-cp37-cp37m-win_amd64.whl (114kB)\n",
      "Collecting chardet (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/8f/8fc49109009e8d2169d94d72e6b1f4cd45c13d147ba7d6170fb41f22b08f/chardet-5.1.0-py3-none-any.whl (199kB)\n",
      "Collecting syntok>1.3.3 (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/47/0d/e9700408c99275692c57ac786edfbede03cf2a9818bd3ecbc4cbf21a4448/syntok-1.4.4-py3-none-any.whl\n",
      "Collecting tika (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/b8/055ed37d6413fef4e4af99cd7e0edc4ddfb8fc167b730b25005d212e2049/tika-2.6.0.tar.gz\n",
      "Collecting transformers>=4.17.0 (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl (7.2MB)\n",
      "Collecting sentencepiece (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/c8/3c1d9ce8f149db100bc775810e51ca58a8d00decb1536ef410ca58f59a9c/sentencepiece-0.1.99-cp37-cp37m-win_amd64.whl (977kB)\n",
      "Collecting keras_bert>=0.86.0 (from ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/0a/ffc65dfa4b31942ee8348e0026d2a7ee57e1769e9266c677141a3e2cac9c/keras-bert-0.89.0.tar.gz\n",
      "Collecting whoosh (from ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.14.6 (from scikit-learn->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/9f/da37cc4a188a1d5d203d65ab28d6504e17594b5342e0c1dc5610ee6f4535/numpy-1.21.6-cp37-cp37m-win_amd64.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl\n",
      "Collecting scipy>=1.1.0 (from scikit-learn->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/40/69/4af412d078cef2298f7d90546fa0e03e65a032558bd85319239c72ae0c3c/scipy-1.7.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.0.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/d9/e9bae85e84737e76ebbcbea13607236da0c0699baed0ae4f1151b728a608/fonttools-4.38.0-py3-none-any.whl (965kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib>=3.0.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.0.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=3.0.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/93/11790e8e81b89acd3a1c8a6b501f8a05b1c41beee0990582699cdda29557/kiwisolver-1.4.4-cp37-cp37m-win_amd64.whl (54kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib>=3.0.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/3c/4f3ef1a14e903d7b2bc43672c20f732b874e1e50a9a58ac9a1726ef3773d/Pillow-9.5.0-cp37-cp37m-win_amd64.whl (2.5MB)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib>=3.0.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/24/6ae4c9c45cf99d96b06b5d99e25526c060303171fb0aea9da2bfd7dbde93/pyparsing-3.1.0-py3-none-any.whl\n",
      "Collecting pytz>=2017.3 (from pandas>=1.0.1->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/99/ad6bd37e748257dd70d6f85d916cafe79c0b0f5e2e95b11f7fbc82bf3110/pytz-2023.3-py2.py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/03/ad9306a50d05c166e3456fe810f33cee2b8b2a7a6818ec5d4908c4ec6b36/urllib3-2.0.3-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2 (from requests->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/19/9f/552f15cb1dade9332d6f0208fa3e6c21bb3eecf1c89862413ed8a3c75900/charset_normalizer-3.2.0-cp37-cp37m-win_amd64.whl (94kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/19/59961b522e6757f0c9097e4493fa906031b95b3ebe9360b2c3083561a6b4/certifi-2023.5.7-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5 (from requests->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl\n",
      "Collecting six (from langdetect->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting regex>2016 (from syntok>1.3.3->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/fc/6e4fab6dc7b1a2d521f2e9dd5380c6b2453770a0f425021d744d29c47a89/regex-2023.6.3-cp37-cp37m-win_amd64.whl (268kB)\n",
      "Collecting setuptools (from tika->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.17.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/c0/4fe04181b0210ee2647cfbb89ecd10a36eef89f10d8aca6a192c201bbe58/PyYAML-6.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting filelock (from transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/06/1f3a3a6fb57bf3e72f63cbf0ae0991540065dd6a13393b89761b38634cb0/tokenizers-0.13.3-cp37-cp37m-win_amd64.whl (3.5MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/25/3c40e748ebd0342ad423c61b1d93d5a776cbfed89d92f9780ab9e58a508f/safetensors-0.3.1-cp37-cp37m-win_amd64.whl (263kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl (268kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/94/64287b38c7de4c90683630338cf28f129decbba0a44f0c6db35a873c73c4/importlib_metadata-6.7.0-py3-none-any.whl\n",
      "Collecting tqdm>=4.27 (from transformers>=4.17.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/02/a2cff6306177ae6bc73bc0665065de51dfb3b9db7373e122e2735faf0d97/tqdm-4.65.0-py3-none-any.whl\n",
      "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/71/de82872c32a803274f9200c63aae9086969143cd569e7bb080a1f291ed0e/keras-transformer-0.40.0.tar.gz\n",
      "Collecting typing-extensions; python_version < \"3.8\" (from kiwisolver>=1.0.1->matplotlib>=3.0.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/64/f0d369ede0ca54fdd520bdee5086dbaf0af81dac53a2ce847bd1ec6e0bf1/fsspec-2023.1.0-py3-none-any.whl (143kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->transformers>=4.17.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/fa/c9e82bbe1af6266adf08afb563905eb87cab83fde00a0a08963510621047/zipp-3.15.0-py3-none-any.whl\n",
      "Collecting colorama; platform_system == \"Windows\" (from tqdm>=4.27->transformers>=4.17.0->ktrain)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl\n",
      "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/f0/8803f9ac4cddd9d2640347bde2f451d7d33bbc99d761f2bc00fb15911bf6/keras-pos-embd-0.13.0.tar.gz\n",
      "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/21/5e1699e9d63a8e3c0d5fd0716b9a8be7d8c2c07fc8de34902e55de5ba58e/keras-multi-head-0.29.0.tar.gz\n",
      "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/a0/b1266b0d852d10ac8339540d09fb90e38c198b6a2bcdeb3a881338d4a8fc/keras-layer-normalization-0.16.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/e7/309d76671f5a7c8c9bae0d516dced34fd6ba50bc417aed6a940565d4b6aa/keras-position-wise-feed-forward-0.8.0.tar.gz\n",
      "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/ac/641978394aaa28d90a81ae3e999ed8206c4c3223b7a668a5aa9ed6034db0/keras-embed-sim-0.10.0.tar.gz\n",
      "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/a5/0a1d003e420da49791f64def11d8d2837280e1a680c2eaaab216f9f17ed7/keras-self-attention-0.51.0.tar.gz\n",
      "Building wheels for collected packages: ktrain, langdetect, jieba, tika, keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py): started\n",
      "  Building wheel for ktrain (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\96\\c6\\ef\\0ca232265180a11265ef7030c317c8d75b5ec5dbab86f02d71\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\7e\\18\\13\\038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "mlflow 1.30.1 has requirement packaging<22, but you'll have packaging 23.1 which is incompatible.\n",
      "mlflow 1.30.1 has requirement pytz<2023, but you'll have pytz 2023.3 which is incompatible.\n",
      "google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.0.3 which is incompatible.\n",
      "databricks-cli 0.17.7 has requirement urllib3<2.0.0,>=1.26.7, but you'll have urllib3 2.0.3 which is incompatible.\n",
      "Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'd:\\\\mlflowenv\\\\lib\\\\site-packages\\\\~cipy\\\\.libs\\\\libansari.54HGNEJBQIYZX5TZPCQGLNVIPFU6NWEX.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "You are using pip version 19.0.3, however version 23.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\af\\e4\\8e\\5fdd61a6b45032936b8f9ae2044ab33e61577950ce8e0dec29\n",
      "  Building wheel for tika (setup.py): started\n",
      "  Building wheel for tika (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\9f\\4c\\4a\\1df66bbb4abd3e83611199595ca2b9371c9d5f306b1cb9d3ce\n",
      "  Building wheel for keras-bert (setup.py): started\n",
      "  Building wheel for keras-bert (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\28\\f2\\01\\9ed7813556c7152f3a08a00f8f55a37588bc6d3f3a05becd2c\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\d5\\94\\7c\\90085b184fcffb3cb41855e16edee459c3af79372506b94b2e\n",
      "  Building wheel for keras-pos-embd (setup.py): started\n",
      "  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\45\\24\\f5\\f9fc1f984155be364d4e1d22256313de4581739b188b359731\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\ef\\46\\be\\ea994fd2765156313585bc298d60a8ac32873e49064de3f8fc\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\e4\\1a\\f8\\ae71722aad5c94d9df57b79c60d0d3c4496d00d2c17cd0d488\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\a5\\97\\cd\\f3aa9f764e3e852d80660fcbd10d4fcd6b7ed023e0f6a339eb\n",
      "  Building wheel for keras-embed-sim (setup.py): started\n",
      "  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\41\\96\\c0\\f0b0a99297dba7f7aa062719fc7a81dd28e826a87ee2978b1a\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\66\\da\\1c\\ed4c7955af6628b059faeff65b3a55675fda33151658a09b1d\n",
      "Successfully built ktrain langdetect jieba tika keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: numpy, joblib, threadpoolctl, scipy, scikit-learn, fonttools, six, python-dateutil, cycler, typing-extensions, kiwisolver, pillow, pyparsing, packaging, matplotlib, pytz, pandas, fastprogress, urllib3, charset-normalizer, certifi, idna, requests, langdetect, jieba, cchardet, chardet, regex, syntok, setuptools, tika, pyyaml, filelock, tokenizers, safetensors, zipp, importlib-metadata, fsspec, colorama, tqdm, huggingface-hub, transformers, sentencepiece, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, whoosh, ktrain\n",
      "  Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Found existing installation: joblib 1.3.1\n",
      "    Uninstalling joblib-1.3.1:\n",
      "      Successfully uninstalled joblib-1.3.1\n",
      "  Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.9\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/fc/6e4fab6dc7b1a2d521f2e9dd5380c6b2453770a0f425021d744d29c47a89/regex-2023.6.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting sacremoses (from transformers==2.9)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/78/fef8d089db5b97546fd6d1ff2e813b8544e85670bf3a8c378c9d0250b98d/sacremoses-0.0.53.tar.gz (880kB)\n",
      "Collecting numpy (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/9f/da37cc4a188a1d5d203d65ab28d6504e17594b5342e0c1dc5610ee6f4535/numpy-1.21.6-cp37-cp37m-win_amd64.whl\n",
      "Collecting tokenizers==0.7.0 (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/f6/553d20014b62001d23dd5727dcc443ed8d72c317e23004faf64b9548ea95/tokenizers-0.7.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting sentencepiece (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/c8/3c1d9ce8f149db100bc775810e51ca58a8d00decb1536ef410ca58f59a9c/sentencepiece-0.1.99-cp37-cp37m-win_amd64.whl\n",
      "Collecting filelock (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl\n",
      "Collecting tqdm>=4.27 (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/02/a2cff6306177ae6bc73bc0665065de51dfb3b9db7373e122e2735faf0d97/tqdm-4.65.0-py3-none-any.whl\n",
      "Collecting requests (from transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting six (from sacremoses->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting click (from sacremoses->transformers==2.9)\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/a6/dc327484918f1656cc9fcebebe77efcfc0ef0d447fa925a8760ee55abe0e/click-8.1.4-py3-none-any.whl (98kB)\n",
      "Collecting joblib (from sacremoses->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/08/9dcdaa5aac4634e4c23af26d92121f7ce445c630efa0d3037881ae2407fb/joblib-1.3.1-py3-none-any.whl\n",
      "Collecting colorama; platform_system == \"Windows\" (from tqdm>=4.27->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/03/ad9306a50d05c166e3456fe810f33cee2b8b2a7a6818ec5d4908c4ec6b36/urllib3-2.0.3-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/19/9f/552f15cb1dade9332d6f0208fa3e6c21bb3eecf1c89862413ed8a3c75900/charset_normalizer-3.2.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/19/59961b522e6757f0c9097e4493fa906031b95b3ebe9360b2c3083561a6b4/certifi-2023.5.7-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from click->sacremoses->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/94/64287b38c7de4c90683630338cf28f129decbba0a44f0c6db35a873c73c4/importlib_metadata-6.7.0-py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->click->sacremoses->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/fa/c9e82bbe1af6266adf08afb563905eb87cab83fde00a0a08963510621047/zipp-3.15.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\" (from importlib-metadata; python_version < \"3.8\"->click->sacremoses->transformers==2.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vasis\\AppData\\Local\\pip\\Cache\\wheels\\56\\d5\\b2\\bc878b2bbddfbcc8fd62ca73c4fd842bd28c1fd3dbdf424c74\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, six, zipp, typing-extensions, importlib-metadata, colorama, click, joblib, tqdm, sacremoses, numpy, tokenizers, sentencepiece, filelock, urllib3, idna, charset-normalizer, certifi, requests, transformers\n",
      "  Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Found existing installation: zipp 3.15.0\n",
      "    Uninstalling zipp-3.15.0:\n",
      "      Successfully uninstalled zipp-3.15.0\n",
      "  Found existing installation: typing-extensions 4.7.1\n",
      "    Uninstalling typing-extensions-4.7.1:\n",
      "      Successfully uninstalled typing-extensions-4.7.1\n",
      "  Found existing installation: importlib-metadata 6.7.0\n",
      "    Uninstalling importlib-metadata-6.7.0:\n",
      "      Successfully uninstalled importlib-metadata-6.7.0\n",
      "  Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Found existing installation: joblib 1.3.1\n",
      "    Uninstalling joblib-1.3.1:\n",
      "      Successfully uninstalled joblib-1.3.1\n",
      "  Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Found existing installation: urllib3 2.0.3\n",
      "    Uninstalling urllib3-2.0.3:\n",
      "      Successfully uninstalled urllib3-2.0.3\n",
      "  Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Found existing installation: charset-normalizer 3.2.0\n",
      "    Uninstalling charset-normalizer-3.2.0:\n",
      "      Successfully uninstalled charset-normalizer-3.2.0\n",
      "  Found existing installation: certifi 2023.5.7\n",
      "    Uninstalling certifi-2023.5.7:\n",
      "      Successfully uninstalled certifi-2023.5.7\n",
      "  Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.2.0 click-8.1.4 colorama-0.4.6 filelock-3.12.2 idna-3.4 importlib-metadata-6.7.0 joblib-1.3.1 numpy-1.21.6 regex-2023.6.3 requests-2.31.0 sacremoses-0.0.53 sentencepiece-0.1.99 six-1.16.0 tokenizers-0.7.0 tqdm-4.65.0 transformers-2.9.0 typing-extensions-4.7.1 urllib3-2.0.3 zipp-3.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mlflow 1.30.1 has requirement importlib-metadata!=4.7.0,<6,>=3.7.0, but you'll have importlib-metadata 6.7.0 which is incompatible.\n",
      "mlflow 1.30.1 has requirement packaging<22, but you'll have packaging 23.1 which is incompatible.\n",
      "google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.0.3 which is incompatible.\n",
      "databricks-cli 0.17.7 has requirement urllib3<2.0.0,>=1.26.7, but you'll have urllib3 2.0.3 which is incompatible.\n",
      "You are using pip version 19.0.3, however version 23.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.9 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'tensorflow.python.keras.engine.keras_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[1;33m from ...modeling_tf_utils import (\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mTFCausalLanguageModelingLoss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_tensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.engine.keras_tensor'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e2c57ceaede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mktrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mktrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArrayLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelease_gpu_memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageClassLearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTTextClassLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerTextClassLearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImagePreprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImagePredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextPreprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBERTPreprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformersPreprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNERPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\text\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_text_classifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_text_regression_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_regression_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtexts_from_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts_from_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts_from_df\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtexts_from_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mentities_from_gmb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_from_conll2003\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_from_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_from_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities_from_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequence_tagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_sequence_taggers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0meda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_topic_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\text\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ktrain\\text\\preprocessor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mDISTILBERT\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'distilbert'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXLNetConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFXLNetForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXLNetTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFXLNetModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXLMConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFXLMForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXLMTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFXLMModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 \u001b[1;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m             ) from e\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'tensorflow.python.keras.engine.keras_tensor'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_sample['content'].tolist(), df_sample['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6485df56f13b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflowenv",
   "language": "python",
   "name": "mlflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
